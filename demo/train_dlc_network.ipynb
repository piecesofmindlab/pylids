{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60585a7b",
   "metadata": {},
   "source": [
    "# Train a new DLC network using labeled frames\n",
    "\n",
    "This notebook provides instruction on how to train a DLC model after labeling frames. The pylids package works on top of the [DeepLabCut](https://github.com/DeepLabCut/DeepLabCut) framework. If you are not familiar with it please check this [link](https://deeplabcut.github.io/DeepLabCut/README.html). Also please run the `select_frames_to_label.ipynb` notebook to select the frames to label before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551135f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "import pylids\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68509955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to DLC config file for your project\n",
    "path_config_file = 'add/path/to/dlc/config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7219b9c",
   "metadata": {},
   "source": [
    "### Create a training dataset for training the network\n",
    "\n",
    "You can verify if this process went through correctly by checking the training-datasets folder inside your DLC project path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53b2c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a training dataset\n",
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc98455",
   "metadata": {},
   "source": [
    "### For training a network from ImageNet weights\n",
    "Run the cell below if you want to train a new model. This step will edit the pose_config.yaml file DLC uses to modify the network training parameters. We will initialize the network with ImageNet model weights and set the appropriate learning rate. For our experiment we set the augmentations to False. You can set it to True if you want to use the augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3680969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Point to the DLC training protocol and explain config and pose config files\n",
    "\n",
    "#read DLC pose config file\n",
    "cfg=deeplabcut.auxiliaryfunctions.read_plainconfig(path_config_file)\n",
    "trainposeconfigfile, testposeconfigfile, snapshotfolder=deeplabcut.return_train_network_path(path_config_file, shuffle=1)\n",
    "cfg_dlc=deeplabcut.auxiliaryfunctions.read_plainconfig(trainposeconfigfile)\n",
    "\n",
    "#pick that as large as your GPU can handle it (lower this if you run out of memory)\n",
    "cfg_dlc['batch_size']=8\n",
    "\n",
    "#set all augmentations to be false \n",
    "cfg_dlc['elastic_transform']=False\n",
    "cfg_dlc['rotation']=0\n",
    "cfg_dlc['covering']=False\n",
    "cfg_dlc['motion_blur'] = False\n",
    "cfg_dlc['mirror'] = False\n",
    "\n",
    "#use adam optimizer instead of sgd\n",
    "cfg_dlc['optimizer'] =\"adam\"\n",
    "\n",
    "#Change the learning rate\n",
    "cfg_dlc['multi_step']=[[0.0001, 40000], [5e-05, 60000], [1e-5, 120000]]\n",
    "\n",
    "deeplabcut.auxiliaryfunctions.write_plainconfig(trainposeconfigfile,cfg_dlc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22159120",
   "metadata": {},
   "source": [
    "### For fine-tuning a network\n",
    "Run the cell below if you want to fine tune a model. This step will edit the pose_config.yaml file DLC uses to modify the network training parameters. We will initialize the network with the baseline model weights and fine tune it using a lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read DLC pose config file\n",
    "cfg=deeplabcut.auxiliaryfunctions.read_plainconfig(path_config_file)\n",
    "trainposeconfigfile, testposeconfigfile, snapshotfolder=deeplabcut.return_train_network_path(path_config_file, shuffle=1)\n",
    "cfg_dlc=deeplabcut.auxiliaryfunctions.read_plainconfig(trainposeconfigfile)\n",
    "\n",
    "#pick that as large as your GPU can handle it (lower this if you run out of memory)\n",
    "cfg_dlc['batch_size']=8\n",
    "\n",
    "#initilize weights with the weights from the pretrained baseline model\n",
    "cfg_dlc['init_weights'] = 'path/to/weights/dlc-models/iteration-0/project_name/train/snapshot-120000'\n",
    "\n",
    "#set all augmentations to be false \n",
    "cfg_dlc['elastic_transform']=False\n",
    "cfg_dlc['rotation']=0\n",
    "cfg_dlc['covering']=False\n",
    "cfg_dlc['motion_blur'] = False\n",
    "cfg_dlc['mirror'] = False\n",
    "\n",
    "#use adam optimizer instead of sgd\n",
    "cfg_dlc['optimizer'] =\"adam\"\n",
    "\n",
    "#Change the learning rate\n",
    "cfg_dlc['multi_step']=[[3e-04, 3000]]\n",
    "\n",
    "deeplabcut.auxiliaryfunctions.write_plainconfig(trainposeconfigfile,cfg_dlc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d0eda",
   "metadata": {},
   "source": [
    "### Train the network\n",
    "\n",
    "Using a GPU, fine tuning a network takes less than an hour while training a network from ImageNet weights takes about half a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e73d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trains the new DLC network\n",
    "deeplabcut.train_network(path_config_file, shuffle=1, displayiters=100, saveiters=500, max_snapshots_to_keep=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75599e1b",
   "metadata": {},
   "source": [
    "### Analyze new eye videos using pylids based on the trained DLC network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811cf7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pylids to analyze the videos\n",
    "\n",
    "#path to the video to analyze\n",
    "video2analyze = 'path/to/eye/video1'\n",
    "\n",
    "#path to the folder where the results will be saved\n",
    "save_folder = 'path/to/save/folder'\n",
    "\n",
    "pylids_out = pylids.analyze_videos(eye_video = video2analyze,\n",
    "                     model_name = path_config_file,\n",
    "                    destfolder=os.path.join(save_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78022665",
   "metadata": {},
   "source": [
    "You can see examples on how to use and analyze the output in the pylids_demo.ipynb notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLC-GPU-LITE",
   "language": "python",
   "name": "dlc-gpu-lite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
